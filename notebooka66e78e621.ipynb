{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/atharvamehta18/notebooka66e78e621?scriptVersionId=156981950\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"**Installing Dependencies**","metadata":{}},{"cell_type":"code","source":"!pip install torch transformers==4.31.0 einops datasets==2.16.0 accelerate trl==0.4.7 peft==0.4.0 bitsandbytes","metadata":{"id":"pZjOziZ5C5Li","outputId":"e9afd9da-7e45-43c8-d27a-4c21746ff08d","execution":{"iopub.status.busy":"2023-12-29T11:25:12.900765Z","iopub.execute_input":"2023-12-29T11:25:12.901057Z","iopub.status.idle":"2023-12-29T11:25:44.523057Z","shell.execute_reply.started":"2023-12-29T11:25:12.901031Z","shell.execute_reply":"2023-12-29T11:25:44.522126Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nCollecting transformers==4.31.0\n  Obtaining dependency information for transformers==4.31.0 from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting datasets==2.16.0\n  Obtaining dependency information for datasets==2.16.0 from https://files.pythonhosted.org/packages/a0/93/da8a22a292e51ab76f969eb87bda8fd70cc3963b4dd71f67bb92a70a7992/datasets-2.16.0-py3-none-any.whl.metadata\n  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\nCollecting trl==0.4.7\n  Obtaining dependency information for trl==0.4.7 from https://files.pythonhosted.org/packages/b9/dd/c34f8b303538103f153e62ed094a3a5a0bed3da80e80aa9bf295ecaa65e1/trl-0.4.7-py3-none-any.whl.metadata\n  Downloading trl-0.4.7-py3-none-any.whl.metadata (10 kB)\nCollecting peft==0.4.0\n  Obtaining dependency information for peft==0.4.0 from https://files.pythonhosted.org/packages/88/a0/6e1c23293a922a9c9e9bd8d56a60cd78ecf531fdabe45ac975e142bfbe86/peft-0.4.0-py3-none-any.whl.metadata\n  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\nCollecting bitsandbytes\n  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/d9/8d/b62d4fb02587e293e5b91b68bbcaa2d88c6a0360b622e9521d4bd07a20cd/bitsandbytes-0.41.3.post2-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.1)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.16.0)\n  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (0.70.15)\nCollecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets==2.16.0)\n  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.16.0) (3.8.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (5.9.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.31.0) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.16.0) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.0) (1.16.0)\nDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.16.0-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.4.7-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, bitsandbytes, pyarrow-hotfix, fsspec, einops, transformers, peft, datasets, trl\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.0\n    Uninstalling tokenizers-0.15.0:\n      Successfully uninstalled tokenizers-0.15.0\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.36.0\n    Uninstalling transformers-4.36.0:\n      Successfully uninstalled transformers-4.36.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.41.3.post2 datasets-2.16.0 einops-0.7.0 fsspec-2023.10.0 peft-0.4.0 pyarrow-hotfix-0.6 tokenizers-0.13.3 transformers-4.31.0 trl-0.4.7\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -i https://test.pypi.org/simple/ bitsandbytes","metadata":{"id":"lq2P8Nh4E6vg","outputId":"3ea5da47-5328-4588-ccbf-5d4657c7e7ce","execution":{"iopub.status.busy":"2023-12-29T11:25:44.524759Z","iopub.execute_input":"2023-12-29T11:25:44.52504Z","iopub.status.idle":"2023-12-29T11:25:56.711332Z","shell.execute_reply.started":"2023-12-29T11:25:44.525016Z","shell.execute_reply":"2023-12-29T11:25:56.710307Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in indexes: https://test.pypi.org/simple/\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.3.post2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip show accelerate","metadata":{"id":"RakA5saQEDE6","outputId":"83745f7a-b784-4b53-d9bd-7e393734b3de","execution":{"iopub.status.busy":"2023-12-29T11:25:56.712663Z","iopub.execute_input":"2023-12-29T11:25:56.712948Z","iopub.status.idle":"2023-12-29T11:26:08.250265Z","shell.execute_reply.started":"2023-12-29T11:25:56.712922Z","shell.execute_reply":"2023-12-29T11:26:08.249146Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Name: accelerate\nVersion: 0.25.0\nSummary: Accelerate\nHome-page: https://github.com/huggingface/accelerate\nAuthor: The HuggingFace team\nAuthor-email: sylvain@huggingface.co\nLicense: Apache\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\nRequired-by: catalyst, peft, trl\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip show bitsandbytes","metadata":{"id":"3Y5NEal3EXch","outputId":"a6352e20-2a7e-4d9b-fb6e-8d5261c71d04","execution":{"iopub.status.busy":"2023-12-29T11:26:08.252393Z","iopub.execute_input":"2023-12-29T11:26:08.25271Z","iopub.status.idle":"2023-12-29T11:26:19.7034Z","shell.execute_reply.started":"2023-12-29T11:26:08.252683Z","shell.execute_reply":"2023-12-29T11:26:19.702157Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Name: bitsandbytes\nVersion: 0.41.3.post2\nSummary: k-bit optimizers and matrix multiplication routines.\nHome-page: https://github.com/TimDettmers/bitsandbytes\nAuthor: Tim Dettmers\nAuthor-email: dettmers@cs.washington.edu\nLicense: MIT\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: \nRequired-by: \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Downloading Tokeniser & Model**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline\n)\nfrom peft import LoraConfig\nfrom trl import SFTTrainer\nimport transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-29T11:26:19.704884Z","iopub.execute_input":"2023-12-29T11:26:19.705216Z","iopub.status.idle":"2023-12-29T11:26:39.646376Z","shell.execute_reply.started":"2023-12-29T11:26:19.705185Z","shell.execute_reply":"2023-12-29T11:26:39.64555Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"name = 'NousResearch/Llama-2-7b-chat-hf'\nllama_tokenizer = AutoTokenizer.from_pretrained(name, trust_remote_code=True)\nllama_tokenizer.pad_token = llama_tokenizer.eos_token\nllama_tokenizer.padding_side = \"right\"  # Fix for fp16","metadata":{"execution":{"iopub.status.busy":"2023-12-29T11:26:39.647503Z","iopub.execute_input":"2023-12-29T11:26:39.648029Z","iopub.status.idle":"2023-12-29T11:26:41.085775Z","shell.execute_reply.started":"2023-12-29T11:26:39.648003Z","shell.execute_reply":"2023-12-29T11:26:41.084731Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a6776bb1804cc2a573f1bf5937adee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ab753345184daf98312fe65bf343c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ecccd6ba334c519157e722edfd4f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158a6a3c0a304bf5a0ed2c26fbe9e244"}},"metadata":{}}]},{"cell_type":"code","source":"\nconfig = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True)\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\n    num_gpus = torch.cuda.device_count()\n    print(f\"{num_gpus} GPU(s) available.\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"Using CPU.\") # For fast initialization directly on GPU!\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n  name,\n  config=config,\n  quantization_config=quant_config,\n  trust_remote_code=True,\n  device_map = \"auto\"\n)\n\n# model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[0, 1], output_device=0)\n\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#     model = torch.nn.parallel.DistributedDataParallel(model)\n\nmodel.to(device)","metadata":{"id":"Up8-8nzBS-Dp","outputId":"7fb8d126-0bec-453a-f34a-9af8e46feb9d","execution":{"iopub.status.busy":"2023-12-29T09:30:42.166775Z","iopub.execute_input":"2023-12-29T09:30:42.167179Z","iopub.status.idle":"2023-12-29T09:30:48.099229Z","shell.execute_reply.started":"2023-12-29T09:30:42.167149Z","shell.execute_reply":"2023-12-29T09:30:48.097874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading Dataset (Psychologist Dataset)**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\ndataset = load_dataset(\"nbertagnolli/counsel-chat\")\nprint(dataset.keys())\ndf = pd.DataFrame(dataset[\"train\"])","metadata":{"id":"QBT7hmpSQXoD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"6-JVK4-orCY2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()\n\ndf.dropna(inplace=True)","metadata":{"id":"m4DCh1egL_wA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = df['questionText'].to_numpy()\noutput_text = df['answerText'].to_numpy()\n\ndf_new = pd.DataFrame()\ndf_new[\"question\"] = input_text\ndf_new[\"answer\"] = output_text","metadata":{"id":"ub13UiuTrhGn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_text.shape","metadata":{"id":"kx6MwI0EsIn3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_standard_format(question,answer) :\n  return \"<s>[INST]  \" + question + \" [/INST] \" + answer + \" </s>\"","metadata":{"id":"VILrZ9JPwSna","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_data = {'text' : [convert_to_standard_format(row[\"question\"],row[\"answer\"]) for _, row in df_new.iterrows()]}\n","metadata":{"id":"FJXENSV0BvoH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trans_df = pd.DataFrame()\ntrans_df[\"text\"] = transformed_data['text'][:100]\ntransformed_data['text'][0]","metadata":{"id":"sq2RFJopMRD7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_data = transformed_data['text'][:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Convert the transformed data to a Hugging Face Dataset\nhf_dataset = Dataset.from_pandas(pd.DataFrame(trans_df))","metadata":{"id":"0AnNldY1NO54","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fine Tuning Params**","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",          # Output directory\n    num_train_epochs=3,              # Total number of training epochs\n    per_device_train_batch_size=8,   # Batch size per device during training\n    per_device_eval_batch_size=8,    # Batch size for evaluation\n    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # Strength of weight decay\n    logging_dir=\"./logs\",            # Directory for storing logs\n    logging_steps=10,\n)","metadata":{"id":"KEDimcJHsLiD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_parameters = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=8,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n# Training Params\ntrain_params = TrainingArguments(\n    output_dir=\"./results_modified\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"adamw_8bit\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\",\n)\n\ntrainer = SFTTrainer(\n    model=name,\n    train_dataset=hf_dataset,\n    peft_config=peft_parameters,\n    dataset_text_field=\"text\",\n    tokenizer=llama_tokenizer,\n    args=train_params\n)","metadata":{"id":"jOHIIsRcwITS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"hsUis0vRwJVT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"refined_model\")","metadata":{"id":"OPjxPhfIwPS6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inference Pipeline**","metadata":{}},{"cell_type":"code","source":"# Generate Text\nquery = \"\"\ntext_gen = pipeline(task=\"text-generation\", model=\"refined_model\", tokenizer=llama_tokenizer, max_length=200)\noutput = text_gen(f\"<s>[INST] {query} [/INST]\")\nprint(output[0]['generated_text'])","metadata":{},"execution_count":null,"outputs":[]}]}